{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "toc: true\n",
    "comments: false\n",
    "layout: post\n",
    "title: Understanding Computer Bias\n",
    "description: Homework and Hacks\n",
    "type: ccc\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Popcorn Hacks\n",
    "1. The Black Mirror episode \"Nosedive\" demonstrates computer bias through a social rating system that determines people’s access to jobs, housing, and services. Those with lower scores face discrimination, similar to real-world AI bias in hiring, policing, and lending. The bias is caused by flawed data, human prejudices in programming, and lack of diverse training data. Like in reality, the system reinforces existing inequalities instead of making fair decisions, showing the dangers of algorithmic bias and AI-driven discrimination.\n",
    "2. When ChatGPT incorrectly solves a problem or doesn't give the correct answer. It made me feel frustrated because I gave it the question and it kept giving me different answers or the wrong one, technology can be improved to be more inclusive by ensuring that AI models are trained on diverse, high-quality data and continuously updated to minimize errors.\n",
    "3. The app only gives recommendations to those who don't have any health/physical conditions and for younger or young adult aged people. To make sure the app is fair and inclusive for all users would be giving recomemendations to people of all ages and conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Hack\n",
    "-  Potential Bias: YouTube’s recommendation algorithm reinforces user preferences, creating filter bubbles where users are repeatedly shown similar content. This can lead to political bias, misinformation spread, or lack of diversity in content suggestions. Also, smaller creators may receive less visibility compared to mainstream content.\n",
    "\n",
    "- Cause of Bias: The bias is likely caused by YouTube’s engagement-driven algorithm, which prioritizes watch time and user interaction. Since the algorithm learns from past behavior, it may overemphasize certain perspectives while ignoring alternative viewpoints. Furthermore, the lack of diverse training data and human oversight can reinforce existing biases in content promotion.\n",
    "\n",
    "- Solution: YouTube could introduce more transparent recommendation controls, allowing users to adjust content diversity in their feeds. Additionally, incorporating randomized content exposure and prioritizing fact-checked, diverse sources would help break filter bubbles and ensure broader representation of voices."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
